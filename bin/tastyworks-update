#!/usr/bin/env python3
"""Get the list of transacttions for a single TW account.

Running this script with `database-filename` and `account-pattern` will
incrementally update a local dbm/Python shelve mapping of unique transaction-id
to JSON/dict data for that account. You can access it with a shelve. Example:

    tastyworks-update transactions.db Margin

Notes:

* The script will automatically avoid fetching again old data.
* It will start at the beginning of the account time creation.
* You can just run this regularly to build a local database of all your
  transactions log.

NOTE: Your username and/or password is not stored anywhere. The session token,
however, is cached and reused as much as possible; where needed, your username
and password can be provided in one of three ways:

- As command-line arguments (--username, --password). Note that this makes them
  visible to procinfo for the root user while the script is running.

- As environment variables (`TW_USER` / `TW_PASSWORD`). Note that this makes
  them visible for the root while the program is running as it is possible
  inspect the environment of any process.

- If not provided, you will be queried on the command-line for their values,
  only when needed. The password is hidden from the console. But you have to
  type it in each time it is needed.

"""

from functools import partial
from typing import Dict, List, Optional, Union
import datetime
import getpass
import logging
import shelve
import os
import re
import pprint
from os import path


import click
import requests
from dateutil import parser


Json = Union[Dict[str, 'Json'], List['Json'], str, int, float]


API_URL = 'https://api.tastyworks.com'
SESSION_TOKEN_CACHE_FILENAME = '~/.tastyworks/scripts/token_cache'


class TastyApiError(Exception):
    """An error occurring due to authentications and/or token refresh."""
    def __init__(self, description, response):
        message = response.json()['error']['message']
        super().__init__(f'{description}: {message}')


class Session:
    """A simple requests session wrapper.
    This inserts the authentication token automatically.
    """
    def __init__(self, session_token):
        self.headers = {'Authorization': session_token}

    def __getattr__(self, name):
        """Delegate a call to requests, adding the auth token along the way."""
        func = getattr(requests, name)
        return partial(func, headers=self.headers)


def GetSession(username: Optional[str], password: Optional[str]) -> Session:
    """A simplistic one-off session getter with no storge nor refresh.
    (This will do for simple tasks.)"""

    cache_filename = path.expanduser(SESSION_TOKEN_CACHE_FILENAME)
    if path.exists(cache_filename):
        with open(cache_filename) as token_file:
            session_token = token_file.read().strip()
        logging.info(f'Reusing cached token "{session_token}" from "{cache_filename}"')

        # Attempt to validate the token.
        session = Session(session_token)
        resp = session.post(f'{API_URL}/sessions/validate')
        if resp.status_code == 201:
            return session
        else:
            logging.info('Expired session token; refreshing new token from credentials')
    else:
        logging.info('Invalid session cache; refreshing new token from credentials')

    # Get a new token from credentials.
    num_retry = 3
    orig_username = username
    orig_password = password
    for _ in range(num_retry):
        username = orig_username
        password = orig_password
        if username is None:
            username = os.getenv('TW_USER')
            if not username:
                username = getpass.getpass('Username: ')
        if password is None:
            password = os.getenv('TW_PASSWORD')
            if not password:
                password = getpass.getpass('Password: ')

        if not username.strip():
            raise TastyApiError(f'No username to acquire token')
        if not password.strip():
            raise TastyApiError(f'No password to acquire token for user {username}')

        resp = requests.post(f'{API_URL}/sessions', json={'login': username,
                                                          'password': password})
        if resp.status_code == 201:
            break
        logging.error(f'Failed to acquire token; try again?')
    else:
        raise TastyApiError(f'Could not log in after {num_retry} trials', resp)

    # Write out the new toklen
    session_token = GetData(resp)['session-token']
    os.makedirs(path.dirname(cache_filename), exist_ok=True)
    with open(cache_filename, 'w') as token_file:
        token_file.write(session_token)

    # Make sure it's valid.
    session = Session(session_token)
    resp = session.post(f'{API_URL}/sessions/validate')
    if resp.status_code != 201:
        raise TastyApiError(f'Could not validate session', resp)

    return session


def GetData(response: requests.Response) -> Json:
    """Get formatted response body with the right types."""
    return response.json(use_decimal=True)['data']


def PaginatedGet(session, url, *args, **kwargs) -> List[Json]:
    """Do a paginated GET request and accumulate all 'items' field in a list."""
    per_page = 1024

    page_offset = 0
    total_pages = None
    total_items = 0
    all_items = []
    while total_pages is None or page_offset < total_pages:
        logging.info(f"Getting page {page_offset} for {url}")
        params = kwargs.pop('params', {})
        params.update({'per-page': per_page,
                       'page-offset': page_offset})
        kwargs['params'] = params
        resp = session.get(url, *args, **kwargs)
        if resp.status_code != 200:
            raise TastyApiError(f'Error in paginated requets at {url}', resp)

        page_offset += 1
        json = resp.json(use_decimal=True)
        if total_pages is None:
            pagination = json['pagination']
            total_pages = pagination['total-pages']
            total_items = pagination['total-items']

        items = json['data']['items']
        if items:
            all_items.extend(items)

    assert len(all_items) == total_items, (
        "Could not fetch some items in paginated request.")
    return all_items


def GetAccounts(session: Session) -> List[Json]:
    """Return a list of active accounts."""
    resp = session.get(f'{API_URL}/customers/me/accounts')
    if resp.status_code != 200:
        raise TastyApiError('Could not get trading accounts info', resp)
    items = GetData(resp)['items']
    return [item['account'] for item in items if item['authority-level'] == 'owner']


def GetApproxLatestTime(db: shelve.Shelf) -> Optional[datetime.datetime]:
    """Return the approximately latest time."""
    # In order to do this, we find the largest id, and return the associated
    # date/time on that transaction. The ids are roughly, but not strictly,
    # incremental, so this should be good enough. The benefit of deriving the
    # latest time this way is that we don't have to do any housekeeping to keep
    # a special entry up-to-date, and we also don't have to parse any of the
    # values (this should scale a good amount).
    if len(db) == 0:
        return None
    max_id = max(db.keys())
    txn = db[max_id]
    return parser.parse(txn['executed-at'])


@click.command()
@click.argument('database') # Path to database file.
@click.option('--regexp', '-a') # Name or part of name of the account id or type
                                # or nickname.
@click.option('--username', '-u', help="Tastyworks username.")
@click.option('--password') # Tastyworks password.
def main(database: str, regexp: str, username: Optional[str], password: Optional[str]):
    logging.basicConfig(level=logging.INFO, format='%(levelname)-8s: %(message)s')

    # Open the database and get the latest transaction stored in it from a
    # special slot.
    with shelve.open(database) as db:
        # Get the list of accounts.
        session = GetSession(username, password)
        accounts = GetAccounts(session)

        # Filter down to the chosen account.
        if regexp:
            accounts = [account
                        for account in accounts
                        if any(re.search(regexp, account[field], flags=re.I)
                               for field in ['account-number', 'account-type-name', 'nickname',
                                             'external-id', 'margin-or-cash'])]
        if len(accounts) != 1:
            raise ValueError(f"More than a single account matches pattern '{regexp}': \n"
                             "{}".format(pprint.pformat(accounts)))
        account = next(iter(accounts))

        # Process each of the accounts.
        latest_time = GetApproxLatestTime(db) or parser.parse(account['opened-at'])
        timestr_begin = latest_time.isoformat() + 'Z'
        timestr_end = datetime.datetime.now().isoformat() + 'Z'
        accid = account['account-number']
        logging.info(f'Updating account {accid} from {timestr_begin} to {timestr_end}')

        # Fetch the list of transactions since the latest one.
        transactions = PaginatedGet(
            session, f'{API_URL}/accounts/{accid}/transactions', params = {
                'start-date': timestr_begin,
                'end-date': timestr_end,
            })
        for txn in transactions:
            key = str(txn['id'])
            if key in db:
                logging.info(f'> Skipping transaction {key} (at {txn["executed-at"]})')
                continue
            logging.info(f'> Storing transaction {key} (at {txn["executed-at"]})')
            db[key] = txn


if __name__ == '__main__':
    main()
